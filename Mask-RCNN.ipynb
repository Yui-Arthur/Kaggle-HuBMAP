{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n",
    "from torchvision.datasets import DatasetFolder, VisionDataset\n",
    "# This is for the progress bar.\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "from pathlib import Path\n",
    "import math\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_instance_segmentation(num_classes):\n",
    "    # load an instance segmentation model pre-trained on COCO\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "    # return model\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # now get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # and replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
    "                                                       hidden_layer,\n",
    "                                                       num_classes)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transforms as T\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.PILToTensor())\n",
    "    # transforms.append(T.ConvertImageDtype(torch.float))\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_data(labels):\n",
    "    valid_data = []\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels.iloc[i]['annotations'])):\n",
    "            if labels.iloc[i]['annotations'][j]['type'] == \"blood_vessel\":\n",
    "                valid_data.append(labels.iloc[i]['id'])\n",
    "                break\n",
    "    \n",
    "    return valid_data\n",
    "\n",
    "def gen_mask(annotations):\n",
    "    boxes = []\n",
    "    masks = []\n",
    "    # area = []\n",
    "    for i in range(len(annotations)):\n",
    "\n",
    "        if annotations[i]['type'] == \"blood_vessel\":\n",
    "            pts = np.array(annotations[i]['coordinates'])\n",
    "            # print(pts[0][0])\n",
    "            min_xy = np.min(pts, axis=1)[0]\n",
    "            max_xy = np.max(pts, axis=1)[0]\n",
    "\n",
    "            boxes += [np.concatenate((min_xy, max_xy), axis=0)]\n",
    "\n",
    "            mask = np.zeros((512,512), dtype=np.uint8)\n",
    "            cv2.fillPoly(mask, pts, 1)\n",
    "\n",
    "            # area.append((max_xy[0] - min_xy[0]) * (max_xy[1] - min_xy[1]))\n",
    "\n",
    "            masks += [mask]\n",
    "        # break\n",
    "    boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "    masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "    area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "\n",
    "    return boxes , masks , area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KidneyDataset(Dataset):\n",
    "    def __init__(self , labels , metadata , image_list , tfm):\n",
    "        self.labels = labels\n",
    "        self.matadata = metadata\n",
    "        self.image_list = image_list\n",
    "        self.tfm = tfm\n",
    "        \n",
    "        self.image_with_target = {}\n",
    "\n",
    "        image_path = Path(image_list[0]).parent\n",
    "        print(image_path)\n",
    "        \n",
    "        for idx , col in labels.iterrows():\n",
    "            \n",
    "\n",
    "\n",
    "            # if f\"{image_path}\\\\{col['id']}.tif\" in image_list:\n",
    "            if f\"{image_path}/{col['id']}.tif\" in image_list:\n",
    "                polygons = col['annotations']\n",
    "                # print(polygons[0])\n",
    "                boxes , masks , area = gen_mask(polygons)\n",
    "                iscrowd = torch.zeros((len(boxes),), dtype=torch.int64)\n",
    "                \n",
    "                target = {}\n",
    "                target[\"boxes\"] = boxes\n",
    "                target[\"labels\"] = torch.zeros((len(boxes),), dtype=torch.int64)\n",
    "                target[\"masks\"] = masks\n",
    "                target[\"image_id\"] = torch.tensor([idx])\n",
    "                target[\"area\"] = area\n",
    "                target[\"iscrowd\"] = iscrowd\n",
    "                self.image_with_target[col['id']] = target\n",
    "\n",
    "        # print()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        # id = self.image_list[idx].split('\\\\')[-1].split('.')[0]\n",
    "        id = self.image_list[idx].split('/')[-1].split('.')[0]\n",
    "        img = Image.open(self.image_list[idx])\n",
    "        target = self.image_with_target[id]\n",
    "\n",
    "\n",
    "        if self.tfm is not None:\n",
    "            img, target = self.tfm(img, target)\n",
    "        # print(target)\n",
    "        return img , target\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path(\"hubmap-hacking-the-human-vasculature\")\n",
    "polygon_file = \"polygons.jsonl\"\n",
    "image_folder = \"train\"\n",
    "metadata_file = \"tile_meta.csv\"\n",
    "train_valid_ratio = 0.9\n",
    "\n",
    "labels = pd.read_json(ROOT / polygon_file , lines=True)\n",
    "id_list = get_valid_data(labels)\n",
    "metadata = pd.read_csv(ROOT / metadata_file)\n",
    "image_list = [str(i) for i  in (ROOT / image_folder).glob('*.tif') if i.stem in id_list]\n",
    "train_list = image_list[:int(len(image_list)*train_valid_ratio)]\n",
    "valid_list = image_list[int(len(image_list)*train_valid_ratio):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hubmap-hacking-the-human-vasculature\\train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arthu\\AppData\\Local\\Temp\\ipykernel_16760\\2335065411.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  boxes = torch.as_tensor(boxes, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "train_set = KidneyDataset(labels , metadata , valid_list , get_transform(train=True))\n",
    "\n",
    "# img.shape\n",
    "# target['masks'].shape\n",
    "# target[\"labels\"]\n",
    "# target[\"boxes\"].shape\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n"
     ]
    }
   ],
   "source": [
    "img , target =  train_set[0]\n",
    "target\n",
    "print(len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Initialize a model, and put it on the device specified.\n",
    "model = get_model_instance_segmentation(1).to(device)\n",
    "batch_size = 2\n",
    "n_epochs = 20\n",
    "patience = 10\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0003, weight_decay=1e-5)\n",
    "_exp_name = \"mask-rcnn-model\"\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer , step_size=3 , gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "train_set = KidneyDataset(Path(\"hubmap-hacking-the-human-vasculature\") , \"polygons.jsonl\" , \"tile_meta.csv\" , \"train\" , get_transform(train=True))\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True , collate_fn=utils.collate_fn)\n",
    "# valid_set = KidneyDataset(Path(\"hubmap-hacking-the-human-vasculature\") , \"polygons.jsonl\" , \"tile_meta.csv\" , \"train\" , get_transform(train=False))\n",
    "# valid_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "# trainset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "from engine import train_one_epoch, evaluate\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(model, optimizer, train_loader , device, epoch, print_freq=10)\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = Image.open(\"test.jpg\").convert(\"RGB\")\n",
    "# # img = tfm(img)\n",
    "# model = get_model_instance_segmentation(2)\n",
    "# model.eval()\n",
    " \n",
    "# pred = model(img.unsqueeze(0))\n",
    "# print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pred[0]['masks'].shape)\n",
    "# Image.fromarray(pred[0]['masks'][0,0].mul(255).byte().cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
