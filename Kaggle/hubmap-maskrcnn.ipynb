{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nfrom PIL import Image\nimport torchvision\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n\nimport gc\nimport numpy as np\nimport pandas as pd\nimport torch\nimport os\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\nfrom torchvision.datasets import DatasetFolder, VisionDataset\n# This is for the progress bar.\nfrom tqdm.auto import tqdm\nimport random\nfrom pathlib import Path\nimport math\nimport cv2\n","metadata":{"execution":{"iopub.status.busy":"2023-06-15T14:12:23.639595Z","iopub.execute_input":"2023-06-15T14:12:23.640152Z","iopub.status.idle":"2023-06-15T14:12:28.112792Z","shell.execute_reply.started":"2023-06-15T14:12:23.640121Z","shell.execute_reply":"2023-06-15T14:12:28.111549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/pytorch/vision.git\n%cd vision\n# !git checkout v0.8.2\n\n!cp references/detection/utils.py ../\n!cp references/detection/transforms.py ../\n!cp references/detection/coco_eval.py ../\n!cp references/detection/engine.py ../\n!cp references/detection/coco_utils.py ../\n\n%cd ..\n!rm -r vision\n!pip install pycocotools\n","metadata":{"execution":{"iopub.status.busy":"2023-06-15T14:12:28.118362Z","iopub.execute_input":"2023-06-15T14:12:28.120079Z","iopub.status.idle":"2023-06-15T14:14:35.916623Z","shell.execute_reply.started":"2023-06-15T14:12:28.119995Z","shell.execute_reply":"2023-06-15T14:14:35.915505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model_instance_segmentation(num_classes):\n    # load an instance segmentation model pre-trained on COCO\n    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n    # return model\n    # get number of input features for the classifier\n    in_features = model.roi_heads.box_predictor.cls_score.in_features\n    # replace the pre-trained head with a new one\n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n\n    # now get the number of input features for the mask classifier\n    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n    hidden_layer = 1024\n    # and replace the mask predictor with a new one\n    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n                                                       hidden_layer,\n                                                       num_classes)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-06-15T14:14:35.920138Z","iopub.execute_input":"2023-06-15T14:14:35.920453Z","iopub.status.idle":"2023-06-15T14:14:35.928827Z","shell.execute_reply.started":"2023-06-15T14:14:35.920422Z","shell.execute_reply":"2023-06-15T14:14:35.927830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import transforms as T\n\ndef get_transform(train):\n    transforms = []\n    transforms.append(T.PILToTensor())\n    transforms.append(T.ConvertImageDtype(torch.float))\n    if train:\n        transforms.append(T.RandomHorizontalFlip(0.5))\n    return T.Compose(transforms)","metadata":{"execution":{"iopub.status.busy":"2023-06-15T14:14:35.930429Z","iopub.execute_input":"2023-06-15T14:14:35.931148Z","iopub.status.idle":"2023-06-15T14:14:35.949551Z","shell.execute_reply.started":"2023-06-15T14:14:35.931113Z","shell.execute_reply":"2023-06-15T14:14:35.948608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_valid_data(labels):\n    valid_data = []\n    for i in range(len(labels)):\n        for j in range(len(labels.iloc[i]['annotations'])):\n            if labels.iloc[i]['annotations'][j]['type'] == \"blood_vessel\":\n                valid_data.append(labels.iloc[i]['id'])\n                break\n    \n    return valid_data\n\ndef gen_mask(annotations):\n    boxes = []\n    masks = []\n    # area = []\n    for i in range(len(annotations)):\n\n        if annotations[i]['type'] == \"blood_vessel\":\n            pts = np.array(annotations[i]['coordinates'])\n            # print(pts[0][0])\n            min_xy = np.min(pts, axis=1)[0]\n            max_xy = np.max(pts, axis=1)[0]\n\n            boxes += [np.concatenate((min_xy, max_xy), axis=0)]\n\n            mask = np.zeros((512,512), dtype=np.uint8)\n            cv2.fillPoly(mask, pts, 1)\n\n            # area.append((max_xy[0] - min_xy[0]) * (max_xy[1] - min_xy[1]))\n\n            masks += [mask]\n        # break\n    boxes = torch.as_tensor(boxes, dtype=torch.float32)\n    masks = torch.as_tensor(masks, dtype=torch.uint8)\n    area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n\n    return boxes , masks , area","metadata":{"execution":{"iopub.status.busy":"2023-06-15T14:14:35.953381Z","iopub.execute_input":"2023-06-15T14:14:35.953630Z","iopub.status.idle":"2023-06-15T14:14:35.965739Z","shell.execute_reply.started":"2023-06-15T14:14:35.953609Z","shell.execute_reply":"2023-06-15T14:14:35.964906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class KidneyDataset(Dataset):\n    def __init__(self , labels , metadata , image_list , tfm):\n        self.labels = labels\n        self.matadata = metadata\n        self.image_list = image_list\n        self.tfm = tfm\n        \n        self.image_with_target = {}\n\n        image_path = Path(image_list[0]).parent\n        print(image_path)\n        \n        for idx , col in labels.iterrows():\n            \n            # if f\"{image_path}\\\\{col['id']}.tif\" in image_list:\n            if f\"{image_path}/{col['id']}.tif\" in image_list:\n                polygons = col['annotations']\n                # print(polygons[0])\n                boxes , masks , area = gen_mask(polygons)\n                iscrowd = torch.zeros((len(boxes),), dtype=torch.int64)\n                \n                target = {}\n                target[\"boxes\"] = boxes\n                target[\"labels\"] = torch.ones((len(boxes),), dtype=torch.int64)\n                target[\"masks\"] = masks\n                target[\"image_id\"] = torch.tensor([idx])\n                target[\"area\"] = area\n                target[\"iscrowd\"] = iscrowd\n                self.image_with_target[col['id']] = target\n\n        # print()\n\n    def __len__(self):\n        return len(self.image_list)\n    \n    def __getitem__(self,idx):\n        \n        # id = self.image_list[idx].split('\\\\')[-1].split('.')[0]\n        id = self.image_list[idx].split('/')[-1].split('.')[0]\n        img = Image.open(self.image_list[idx])\n        target = self.image_with_target[id]\n\n\n        if self.tfm is not None:\n            img, target = self.tfm(img, target)\n        # print(target)\n        return img , target\n        ","metadata":{"execution":{"iopub.status.busy":"2023-06-15T14:14:35.966983Z","iopub.execute_input":"2023-06-15T14:14:35.967552Z","iopub.status.idle":"2023-06-15T14:14:35.980404Z","shell.execute_reply.started":"2023-06-15T14:14:35.967520Z","shell.execute_reply":"2023-06-15T14:14:35.979413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT = Path(\"/kaggle/input/hubmap-hacking-the-human-vasculature\")\npolygon_file = \"polygons.jsonl\"\nimage_folder = \"train\"\nmetadata_file = \"tile_meta.csv\"\ntrain_valid_ratio = 0.9\n\nlabels = pd.read_json(ROOT / polygon_file , lines=True)\nid_list = get_valid_data(labels)\nmetadata = pd.read_csv(ROOT / metadata_file)\nimage_list = [str(i) for i  in (ROOT / image_folder).glob('*.tif') if i.stem in id_list]\ntrain_list = image_list[:int(len(image_list)*train_valid_ratio)]\nvalid_list = image_list[int(len(image_list)*train_valid_ratio):]","metadata":{"execution":{"iopub.status.busy":"2023-06-15T14:14:35.981778Z","iopub.execute_input":"2023-06-15T14:14:35.982174Z","iopub.status.idle":"2023-06-15T14:14:41.025135Z","shell.execute_reply.started":"2023-06-15T14:14:35.982143Z","shell.execute_reply":"2023-06-15T14:14:41.024146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# train_set = KidneyDataset(labels , metadata , train_list , get_transform(train=True))\n\n# # img , target = train_set[0]\n# for i , j in train_set:\n#     pass\n#     break\n","metadata":{"execution":{"iopub.status.busy":"2023-06-15T14:14:41.026686Z","iopub.execute_input":"2023-06-15T14:14:41.027078Z","iopub.status.idle":"2023-06-15T14:14:41.032801Z","shell.execute_reply.started":"2023-06-15T14:14:41.027044Z","shell.execute_reply":"2023-06-15T14:14:41.030826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Initialize a model, and put it on the device specified.\nmodel = get_model_instance_segmentation(2).to(device)\nbatch_size = 2\nn_epochs = 20\npatience = 10\noptimizer = torch.optim.SGD(model.parameters(), lr=0.0003, weight_decay=1e-5)\n_exp_name = \"mask-rcnn-model\"\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer , step_size=3 , gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2023-06-15T14:14:41.034371Z","iopub.execute_input":"2023-06-15T14:14:41.035376Z","iopub.status.idle":"2023-06-15T14:14:48.414023Z","shell.execute_reply.started":"2023-06-15T14:14:41.035343Z","shell.execute_reply":"2023-06-15T14:14:48.413009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import utils\ntrain_set = KidneyDataset(labels , metadata , train_list , get_transform(train=True))\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True , collate_fn=utils.collate_fn)\nvalid_set = KidneyDataset(labels , metadata , valid_list , get_transform(train=False))\nvalid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True , collate_fn=utils.collate_fn)\n# valid_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n# trainset[0]\n","metadata":{"execution":{"iopub.status.busy":"2023-06-15T14:14:48.415333Z","iopub.execute_input":"2023-06-15T14:14:48.416337Z","iopub.status.idle":"2023-06-15T14:33:27.757967Z","shell.execute_reply.started":"2023-06-15T14:14:48.416302Z","shell.execute_reply":"2023-06-15T14:33:27.756908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 10\nfrom engine import train_one_epoch, evaluate\n\nfor epoch in range(num_epochs):\n    # train for one epoch, printing every 10 iterations\n    train_one_epoch(model, optimizer, train_loader , device, epoch, print_freq=10)\n    # update the learning rate\n    lr_scheduler.step()\n    evaluate(model, valid_loader, device=device)\n    torch.save(model.state_dict(), f\"{_exp_name}_best.ckpt\")","metadata":{"execution":{"iopub.status.busy":"2023-06-15T14:33:27.759603Z","iopub.execute_input":"2023-06-15T14:33:27.760032Z","iopub.status.idle":"2023-06-15T15:15:02.319701Z","shell.execute_reply.started":"2023-06-15T14:33:27.759994Z","shell.execute_reply":"2023-06-15T15:15:02.318506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# img = Image.open(\"test.jpg\").convert(\"RGB\")\n# # img = tfm(img)\n# model = get_model_instance_segmentation(2)\n# model.eval()\n \n# pred = model(img.unsqueeze(0))\n# print(pred)","metadata":{"execution":{"iopub.status.busy":"2023-06-15T15:15:02.323543Z","iopub.execute_input":"2023-06-15T15:15:02.323857Z","iopub.status.idle":"2023-06-15T15:15:02.330814Z","shell.execute_reply.started":"2023-06-15T15:15:02.323830Z","shell.execute_reply":"2023-06-15T15:15:02.329955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(pred[0]['masks'].shape)\n# Image.fromarray(pred[0]['masks'][0,0].mul(255).byte().cpu().numpy())","metadata":{"execution":{"iopub.status.busy":"2023-06-15T15:15:02.333708Z","iopub.execute_input":"2023-06-15T15:15:02.334132Z","iopub.status.idle":"2023-06-15T15:15:02.345577Z","shell.execute_reply.started":"2023-06-15T15:15:02.334106Z","shell.execute_reply":"2023-06-15T15:15:02.344701Z"},"trusted":true},"execution_count":null,"outputs":[]}]}